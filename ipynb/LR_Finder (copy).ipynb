{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70e6d2ce-d769-4b82-8484-01a7efa5cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class LRFinder(Callback):\n",
    "    \"\"\"`Callback` that exponentially adjusts the learning rate after each training batch between `start_lr` and\n",
    "    `end_lr` for a maximum number of batches: `max_step`. The loss and learning rate are recorded at each step allowing\n",
    "    visually finding a good learning rate as per https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html via\n",
    "    the `plot` method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, start_lr: float = 1e-7, end_lr: float = 1, max_steps: int = 1000, smoothing=0.9):\n",
    "        super(LRFinder, self).__init__()\n",
    "        self.start_lr, self.end_lr = start_lr, end_lr\n",
    "        self.max_steps = max_steps\n",
    "        self.smoothing = smoothing\n",
    "        self.step, self.best_loss, self.avg_loss, self.lr = 0, 0, 0, 0\n",
    "        self.lrs, self.losses = [], []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.step, self.best_loss, self.avg_loss, self.lr = 0, 0, 0, 0\n",
    "        self.lrs, self.losses = [], []\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.lr = self.exp_annealing(self.step)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, self.lr)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        step = self.step\n",
    "        if loss:\n",
    "            self.avg_loss = self.smoothing * self.avg_loss + (1 - self.smoothing) * loss\n",
    "            smooth_loss = self.avg_loss / (1 - self.smoothing ** (self.step + 1))\n",
    "            self.losses.append(smooth_loss)\n",
    "            self.lrs.append(self.lr)\n",
    "\n",
    "            if step == 0 or loss < self.best_loss:\n",
    "                self.best_loss = loss\n",
    "\n",
    "            if smooth_loss > 4 * self.best_loss or tf.math.is_nan(smooth_loss):\n",
    "                self.model.stop_training = True\n",
    "\n",
    "        if step == self.max_steps:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "        self.step += 1\n",
    "\n",
    "    def exp_annealing(self, step):\n",
    "        return self.start_lr * (self.end_lr / self.start_lr) ** (step * 1. / self.max_steps)\n",
    "\n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate (log scale)')\n",
    "        ax.set_xscale('log')\n",
    "        ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
    "        ax.plot(self.lrs, self.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4843309-2210-44e4-a668-5ed64210ed0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " model_10 (Functional)       (None, 8, 8, 256)         1735488   \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 160)         41120     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 160)         640160    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4, 4, 160)        16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 4, 4, 160)         0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 160)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 640)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,416,784\n",
      "Trainable params: 2,416,776\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models import mobilenet\n",
    "clf = mobilenet.create_model(input_shape = (64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b9715e8-e3cf-47f7-84fa-423b476d0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.gtsrb_template_loader import GTSRB_Template_DataGenerator\n",
    "from data_loader.tt100k_template_loader import TT100K_Template_DataGenerator\n",
    "train_datagen = GTSRB_Template_DataGenerator(n_way=43,k_shot=1,n_query=50,batch=128,data_type='all',target_size=(64,64),augmentation=True)\n",
    "val_datagen = TT100K_Template_DataGenerator(n_way=36,k_shot=1,n_query=50,batch=128,data_type='all',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea894468-882d-4812-ad51-5a058a1f5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fun(y_true,y_pred):\n",
    "    x = -tf.math.log(y_pred + 1e-12)\n",
    "    return tf.reduce_mean(y_true*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f170a505-01e1-4e90-aadd-e9ff7be133e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LRFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "083d0b1c-3cb3-4721-a4e2-ad4f7866635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "train_metric = CategoricalAccuracy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1.0,epsilon=1.0e-8)\n",
    "#optimizer = keras.optimizers.SGD(learning_rate=args.lr,momentum=0.9)\n",
    "train_loss_tracker = keras.metrics.Mean(name='train_loss')\n",
    "clf.compile(optimizer=optimizer,loss=loss_fun,metrics=train_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea349dd-bf5b-4acd-bd96-5a5775190b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/306 [====================>.........] - ETA: 14s - loss: 0.4305 - categorical_accuracy: 0.2044"
     ]
    }
   ],
   "source": [
    "clf.fit(train_datagen,epochs=1,callbacks=[lr_finder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db939865-0fa9-41d9-842b-3e9bc3e52782",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c71f4a16-8e3c-44a4-a9ed-3a76cd1c80a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.055085354483839e-05"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_finder.lrs[np.where(np.round(lr_finder.losses,1) == 0.2)[0][30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035ddae0-f961-4812-9d32-866ae8bdbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bb76218-7e00-4525-b68a-6290959be6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 310,  311,  312,  313,  314,  315,  316,  317,  318,  319,  320,\n",
       "         321,  322,  323,  324,  325,  326,  327,  328,  329,  330,  331,\n",
       "         332,  333,  334,  335,  336,  337,  338,  339,  340,  341,  342,\n",
       "         343,  934,  935,  936,  937,  938,  939,  940,  941,  942,  943,\n",
       "         944,  945,  946,  947,  948,  949,  950,  951,  952,  953,  954,\n",
       "         955,  956,  957,  958,  959,  960,  961,  962,  963,  964,  965,\n",
       "         966,  967,  968,  969,  970,  971,  972,  973,  974,  975,  976,\n",
       "         977,  978,  979,  980,  981,  982,  983,  984,  985,  986,  987,\n",
       "         988,  989,  990,  991,  992,  993,  994,  995,  996,  997,  998,\n",
       "         999, 1000], dtype=int64),)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.round(lr_finder.losses,1) == 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87c22845-f7fb-4f42-8ac1-13bf4944d3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33817973732948303,\n",
       " 0.3533873918809389,\n",
       " 0.35814583070603684,\n",
       " 0.3609086167209194,\n",
       " 0.36090319757583694,\n",
       " 0.3591608443446838,\n",
       " 0.35559337200857505,\n",
       " 0.3527240910087585,\n",
       " 0.3494280388661613,\n",
       " 0.3471104651185252,\n",
       " 0.34551547553338313,\n",
       " 0.3436954799065329,\n",
       " 0.3428566279175859,\n",
       " 0.3426399540774288,\n",
       " 0.34222741348000263,\n",
       " 0.34243482501013556,\n",
       " 0.3423485290657568,\n",
       " 0.34207417186304506,\n",
       " 0.34217983567327925,\n",
       " 0.3418277778598562,\n",
       " 0.3415852149527821,\n",
       " 0.3416083591247597,\n",
       " 0.3417372272364325,\n",
       " 0.3419178205442153,\n",
       " 0.3417664434303121,\n",
       " 0.34173566618362705,\n",
       " 0.3418070570267703,\n",
       " 0.3418134295167916,\n",
       " 0.34176384707552904,\n",
       " 0.34161216733177796,\n",
       " 0.3416395010657744,\n",
       " 0.3417038101010756,\n",
       " 0.3417735440715891,\n",
       " 0.3418488321207574,\n",
       " 0.3420829166377933,\n",
       " 0.34234476100240396,\n",
       " 0.3425580870023376,\n",
       " 0.34284992290326505,\n",
       " 0.3432686153413303,\n",
       " 0.34387689092625884,\n",
       " 0.34439567162446744,\n",
       " 0.344888532990783,\n",
       " 0.34526981715321003,\n",
       " 0.34550308727525636,\n",
       " 0.3456867892231056,\n",
       " 0.34596192224106753,\n",
       " 0.3460210754632904,\n",
       " 0.34604855325480016,\n",
       " 0.3459556799741578,\n",
       " 0.34578984758584036,\n",
       " 0.34562921325756446,\n",
       " 0.34549522015586587,\n",
       " 0.34541283541644624,\n",
       " 0.34534615524230206,\n",
       " 0.34531005286290384,\n",
       " 0.34521352194064686,\n",
       " 0.3451006486004498,\n",
       " 0.34494407374507013,\n",
       " 0.3447193164079353,\n",
       " 0.34437677326192767,\n",
       " 0.3440843895575178,\n",
       " 0.3438245097901652,\n",
       " 0.343643240698406,\n",
       " 0.34337063110645033,\n",
       " 0.34303153364096123,\n",
       " 0.34261900851868377,\n",
       " 0.34235932265325614,\n",
       " 0.3420238507633626,\n",
       " 0.34172107176339706,\n",
       " 0.34135936541002304,\n",
       " 0.34105981244557615,\n",
       " 0.34072292503819945,\n",
       " 0.3403390143211931,\n",
       " 0.3399625178644785,\n",
       " 0.33956943420685787,\n",
       " 0.3392472905228813,\n",
       " 0.33893678201653743,\n",
       " 0.3386208869535597,\n",
       " 0.3383243458609163,\n",
       " 0.3379746367865244,\n",
       " 0.3376193382395476,\n",
       " 0.3372374280214392,\n",
       " 0.3368154393610942,\n",
       " 0.3363746184320205,\n",
       " 0.3359254178450326,\n",
       " 0.3354805677549351,\n",
       " 0.3350452328275767,\n",
       " 0.3346757581149167,\n",
       " 0.33427238837881523,\n",
       " 0.3338184223301436,\n",
       " 0.3334061696768747,\n",
       " 0.3329483072742918,\n",
       " 0.33250539532418644,\n",
       " 0.33205323371402784,\n",
       " 0.3316305323818895,\n",
       " 0.33121650727757723,\n",
       " 0.33081705585997806,\n",
       " 0.33039826464544203,\n",
       " 0.3299171125022008,\n",
       " 0.3294654662266779,\n",
       " 0.3290525106585996,\n",
       " 0.3286539762104473,\n",
       " 0.3282597449574941,\n",
       " 0.3278361175580541,\n",
       " 0.3273581740510782,\n",
       " 0.32693978350123853,\n",
       " 0.32650207798605385,\n",
       " 0.32610451709483046,\n",
       " 0.32563210118579633,\n",
       " 0.32514046799689866,\n",
       " 0.3246373179776021,\n",
       " 0.32412691417905104,\n",
       " 0.3236788019405119,\n",
       " 0.32323345612875737,\n",
       " 0.3227597336318813,\n",
       " 0.32231577359794855,\n",
       " 0.3218204964200215,\n",
       " 0.3213202357315324,\n",
       " 0.3208082270153346,\n",
       " 0.32031430307223097,\n",
       " 0.319830277674078,\n",
       " 0.3193359920381882,\n",
       " 0.3188885722057795,\n",
       " 0.3184420522673817,\n",
       " 0.31803387235865477,\n",
       " 0.31759727371449176,\n",
       " 0.31718633742681873,\n",
       " 0.31681565744208423,\n",
       " 0.3164381258162762,\n",
       " 0.3160204142819958,\n",
       " 0.3156375419632942,\n",
       " 0.31526657293010835,\n",
       " 0.31483885625452795,\n",
       " 0.31437919981602475,\n",
       " 0.31394526435483205,\n",
       " 0.313480690501233,\n",
       " 0.31300387838025984,\n",
       " 0.31254859894983633,\n",
       " 0.31209124721430065,\n",
       " 0.3116636417379867,\n",
       " 0.31122165682829717,\n",
       " 0.310737866869953,\n",
       " 0.31028100719911333,\n",
       " 0.3098431306324636,\n",
       " 0.3094275006202934,\n",
       " 0.30892722076600215,\n",
       " 0.3084878467666864,\n",
       " 0.30806372246259955,\n",
       " 0.30762601501048903,\n",
       " 0.30718576550090865,\n",
       " 0.30677466959303323,\n",
       " 0.3063591691737714,\n",
       " 0.3059264933230638,\n",
       " 0.3054841382549216,\n",
       " 0.3050240000632403,\n",
       " 0.30455139161608574,\n",
       " 0.30408393929635313,\n",
       " 0.3035833321833793,\n",
       " 0.3030534609416014,\n",
       " 0.3025152317260097,\n",
       " 0.30197802466001583,\n",
       " 0.3014467622001393,\n",
       " 0.3009235559364377,\n",
       " 0.30042263850135476,\n",
       " 0.29989522680253017,\n",
       " 0.29937021419215804,\n",
       " 0.2988579942300977,\n",
       " 0.2983455008325533,\n",
       " 0.2978143703294726,\n",
       " 0.2972578386589291,\n",
       " 0.296673689486969,\n",
       " 0.2960640497742859,\n",
       " 0.29543224939582036,\n",
       " 0.2947878745325534,\n",
       " 0.2941555595748388,\n",
       " 0.29352258887500876,\n",
       " 0.29288281422294704,\n",
       " 0.29223648388015894,\n",
       " 0.29159552167384706,\n",
       " 0.2909470436880706,\n",
       " 0.29030003886269845,\n",
       " 0.2896495438263297,\n",
       " 0.28899497478734026,\n",
       " 0.2883204670778811,\n",
       " 0.2876173870567936,\n",
       " 0.28692817241972857,\n",
       " 0.2862318416012227,\n",
       " 0.2855405771333205,\n",
       " 0.2848338929039648,\n",
       " 0.2841091466432222,\n",
       " 0.28339825384058914,\n",
       " 0.28268200438118335,\n",
       " 0.2819611842701802,\n",
       " 0.281243230276642,\n",
       " 0.2805357146612337,\n",
       " 0.27981897011484896,\n",
       " 0.2791163040549469,\n",
       " 0.2783995580682692,\n",
       " 0.27768319654493834,\n",
       " 0.27695506341432197,\n",
       " 0.27622680241277464,\n",
       " 0.27548852897611376,\n",
       " 0.2747671127636935,\n",
       " 0.27406266513312383,\n",
       " 0.27337412103544867,\n",
       " 0.27269101200553075,\n",
       " 0.2719923739852839,\n",
       " 0.27128588425099254,\n",
       " 0.270573529007652,\n",
       " 0.26986051118590454,\n",
       " 0.26914338633001084,\n",
       " 0.26841381518152935,\n",
       " 0.2676940977104886,\n",
       " 0.26699119384829234,\n",
       " 0.2662907413458763,\n",
       " 0.26557311461701,\n",
       " 0.2648556653826645,\n",
       " 0.264120741859228,\n",
       " 0.26338627413666754,\n",
       " 0.262661872587349,\n",
       " 0.26194138671310285,\n",
       " 0.26122558425676207,\n",
       " 0.26051280478363986,\n",
       " 0.2598161540602568,\n",
       " 0.2591363169706945,\n",
       " 0.25847553115696437,\n",
       " 0.257821192457745,\n",
       " 0.2571657807658098,\n",
       " 0.25651690462497534,\n",
       " 0.2558645138078822,\n",
       " 0.25521320810321246,\n",
       " 0.25455316642285725,\n",
       " 0.2538822120966885,\n",
       " 0.25320503650983195,\n",
       " 0.2525340843696478,\n",
       " 0.25187076435973926,\n",
       " 0.25121133303483983,\n",
       " 0.25054528661823006,\n",
       " 0.24986478550661967,\n",
       " 0.24918864843334473,\n",
       " 0.24851955333726122,\n",
       " 0.2478493186179627,\n",
       " 0.24717483660672054,\n",
       " 0.24650168783450216,\n",
       " 0.2458252313761439,\n",
       " 0.24514810470001258,\n",
       " 0.24447203928759081,\n",
       " 0.24379401434537806,\n",
       " 0.2431204813338226,\n",
       " 0.24245098360927808,\n",
       " 0.241778248207733,\n",
       " 0.24110424398508318,\n",
       " 0.24043910246306463,\n",
       " 0.23977919257772234,\n",
       " 0.2391210645773301,\n",
       " 0.23846651169701893,\n",
       " 0.23780765878895832,\n",
       " 0.23715305251842558,\n",
       " 0.23650084814100608,\n",
       " 0.2358516578138088,\n",
       " 0.23520065613927302,\n",
       " 0.2345580616743128,\n",
       " 0.23391903720653837,\n",
       " 0.23328151359280994,\n",
       " 0.23264861602295336,\n",
       " 0.23201776592769188,\n",
       " 0.23138855292354155,\n",
       " 0.23075850809175455,\n",
       " 0.2301283091714261,\n",
       " 0.22950794938894586,\n",
       " 0.22888530621253653,\n",
       " 0.2282650485276268,\n",
       " 0.2276460154031888,\n",
       " 0.22702894269006013,\n",
       " 0.22641316645064838,\n",
       " 0.22580263250516835,\n",
       " 0.22519543975693257,\n",
       " 0.22458456048460834,\n",
       " 0.22397137512944953,\n",
       " 0.22336456921860104,\n",
       " 0.22276017141787274,\n",
       " 0.22216183160944036,\n",
       " 0.2215680499244026,\n",
       " 0.22097864771201828,\n",
       " 0.2203896405486579,\n",
       " 0.21980126460090113,\n",
       " 0.21921678715671442,\n",
       " 0.2186328426038504,\n",
       " 0.21805083647685766,\n",
       " 0.21747138257608578,\n",
       " 0.2168919979553142,\n",
       " 0.21631365171260106,\n",
       " 0.21573398099410354,\n",
       " 0.21515917258919315,\n",
       " 0.21458832750434606,\n",
       " 0.2140198275123381,\n",
       " 0.21345207911798447,\n",
       " 0.21288681914272087,\n",
       " 0.2123270054745273,\n",
       " 0.21176847995110715,\n",
       " 0.21121443224658096,\n",
       " 0.21065915297904186,\n",
       " 0.21010849778150234,\n",
       " 0.20955804649854942,\n",
       " 0.20900810805438677,\n",
       " 0.20846510273944185,\n",
       " 0.19300157994983347,\n",
       " 0.17882701050601368,\n",
       " 0.16563366614009697,\n",
       " 0.15404614183806556,\n",
       " 0.14363865590247366,\n",
       " 0.13426066967385575,\n",
       " 0.12595239087227786,\n",
       " 0.11843570109561503,\n",
       " 0.11168696503062918,\n",
       " 0.10555423739749079,\n",
       " 0.09997214288888469,\n",
       " 0.09491246151666129,\n",
       " 0.09031853377288833,\n",
       " 0.08615404486178982,\n",
       " 0.08249563160109186,\n",
       " 0.07921035937280355,\n",
       " 0.0761852668387672,\n",
       " 0.07344885081019825,\n",
       " 0.0709434717294588,\n",
       " 0.06868869351419934,\n",
       " 0.06665773275857981,\n",
       " 0.0648058343681617,\n",
       " 0.06314633313592583,\n",
       " 0.06166147089400568,\n",
       " 0.06033535097299825,\n",
       " 0.0591106519334806,\n",
       " 0.05796451838910219,\n",
       " 0.05693705280512247,\n",
       " 0.05598875045677727,\n",
       " 0.05510286161214745,\n",
       " 0.05430806504706116,\n",
       " 0.05357384713309621,\n",
       " 0.052883334742345946,\n",
       " 0.05224177192422021,\n",
       " 0.0516421425411606,\n",
       " 0.051072136214629194,\n",
       " 0.050542202056576654,\n",
       " 0.050059292654213175,\n",
       " 0.049628304487481886,\n",
       " 0.04923371855558322,\n",
       " 0.048877525038790996,\n",
       " 0.04853717777783182,\n",
       " 0.048213743808756836,\n",
       " 0.04793346998949996,\n",
       " 0.047653861667455596,\n",
       " 0.047384522401459246,\n",
       " 0.047129751705974846,\n",
       " 0.046886456576452115,\n",
       " 0.04666004931998145,\n",
       " 0.046462156826900455,\n",
       " 0.046285931874496054,\n",
       " 0.04611530790553896,\n",
       " 0.04595299897932775,\n",
       " 0.04579867464313299,\n",
       " 0.04565610848673633,\n",
       " 0.045512034635023346,\n",
       " 0.04538367090249903,\n",
       " 0.04525821936987204,\n",
       " 0.04514390632089105,\n",
       " 0.04503618467965239,\n",
       " 0.0449381243209706,\n",
       " 0.04483978973513838,\n",
       " 0.044738707557493415,\n",
       " 0.0446398683922058,\n",
       " 0.044542679879358324,\n",
       " 0.04445117572840236,\n",
       " 0.04435450495686695,\n",
       " 0.044256807444154306,\n",
       " 0.04416592180221595,\n",
       " 0.04408190854927288,\n",
       " 0.044002982603374596,\n",
       " 0.043922515326914324,\n",
       " 0.043835521442452494,\n",
       " 0.04375118750580498,\n",
       " 0.04366203834040476,\n",
       " 0.043576400557966646,\n",
       " 0.043493758734892266,\n",
       " 0.043420820546296646,\n",
       " 0.04334552879227466,\n",
       " 0.043267504901527754,\n",
       " 0.04319614979401772,\n",
       " 0.043127282525082335,\n",
       " 0.043054098172467865,\n",
       " 0.04298316586030893,\n",
       " 0.042919073832154625,\n",
       " 0.042863496913421464,\n",
       " 0.04281035589329152,\n",
       " 0.0427601354761578,\n",
       " 0.0427210923978976,\n",
       " 0.04267959232174977,\n",
       " 0.042640107289346675,\n",
       " 0.04260304711645182,\n",
       " 0.04256757774101498,\n",
       " 0.042526524244071266,\n",
       " 0.042484235148121025,\n",
       " 0.04243309621258596,\n",
       " 0.04237116120079773,\n",
       " 0.04230910159784213,\n",
       " 0.042247218200305005,\n",
       " 0.042182636462514606,\n",
       " 0.04211057807761282,\n",
       " 0.04203677291355595,\n",
       " 0.04196810973896443,\n",
       " 0.0419017214615392,\n",
       " 0.041833384472660474,\n",
       " 0.041765130584119785,\n",
       " 0.04169692280114802,\n",
       " 0.04163354164857667,\n",
       " 0.04156617173402609,\n",
       " 0.04150106361969502,\n",
       " 0.0414375653248804,\n",
       " 0.04137721236483251,\n",
       " 0.041319094532155945,\n",
       " 0.04125738659509178,\n",
       " 0.04119748229391714,\n",
       " 0.04113535192257768,\n",
       " 0.04107566869240945,\n",
       " 0.041019344591933,\n",
       " 0.040966443059299154,\n",
       " 0.04091254376243391,\n",
       " 0.0408577487129346,\n",
       " 0.04079893591329832,\n",
       " 0.040742004549432206,\n",
       " 0.040690653445656665,\n",
       " 0.0406408317437788,\n",
       " 0.04059039831617655,\n",
       " 0.04054028791599734,\n",
       " 0.040493493176221224,\n",
       " 0.040443570074486165,\n",
       " 0.04039456605051228,\n",
       " 0.040346858210572024,\n",
       " 0.04029880186069764,\n",
       " 0.04025145779683075,\n",
       " 0.04020155849129452,\n",
       " 0.04015105335775459,\n",
       " 0.04010034123537043,\n",
       " 0.040047633449528504,\n",
       " 0.039997379377747076,\n",
       " 0.03994765577786967,\n",
       " 0.03989799870318596,\n",
       " 0.039846098526714065,\n",
       " 0.039791450891850426,\n",
       " 0.03974099844153944,\n",
       " 0.03969274623205861,\n",
       " 0.039646425810551056,\n",
       " 0.03959909771421141,\n",
       " 0.039551852520155195,\n",
       " 0.03950654532836135,\n",
       " 0.03945922016793122,\n",
       " 0.03940540918433932,\n",
       " 0.03935764873377323,\n",
       " 0.03931589106635904,\n",
       " 0.03926972870454183,\n",
       " 0.03922312400721006,\n",
       " 0.039176353293500776,\n",
       " 0.03912504291043499,\n",
       " 0.039070472721807525,\n",
       " 0.03901228623499187,\n",
       " 0.0389541982136045,\n",
       " 0.03889846714036531,\n",
       " 0.038842828899891976,\n",
       " 0.03878781996393663,\n",
       " 0.038733581920484865,\n",
       " 0.038679254251736545,\n",
       " 0.038624802334324845,\n",
       " 0.038572919684543905,\n",
       " 0.03851811385264518,\n",
       " 0.038461986223851344,\n",
       " 0.03841084401905063,\n",
       " 0.03835281687467864,\n",
       " 0.038290306918229794,\n",
       " 0.03822946696794582,\n",
       " 0.038169453510492016,\n",
       " 0.038111115591689025,\n",
       " 0.038052812677887744,\n",
       " 0.03799123507344812,\n",
       " 0.03793375924173674,\n",
       " 0.0378760735089512,\n",
       " 0.03781851216211301,\n",
       " 0.03776650019634707,\n",
       " 0.037717387197753284,\n",
       " 0.037669912831491674,\n",
       " 0.03762019055173377,\n",
       " 0.0375690005906127,\n",
       " 0.03752094814369399,\n",
       " 0.03747375809421527,\n",
       " 0.03742434608880032,\n",
       " 0.03737346331426515,\n",
       " 0.03733049370481682,\n",
       " 0.03728511441618901,\n",
       " 0.03724080145839484,\n",
       " 0.03719543654158978,\n",
       " 0.03714897659512104,\n",
       " 0.03709882209084995,\n",
       " 0.037047477448426784,\n",
       " 0.0369966959665207,\n",
       " 0.0369435308763374,\n",
       " 0.03688780032595895,\n",
       " 0.036830955189474546,\n",
       " 0.03677273588658106,\n",
       " 0.03671510410857855,\n",
       " 0.03665784426825636,\n",
       " 0.036600888996995026,\n",
       " 0.03654161764354396,\n",
       " 0.03647971829626758,\n",
       " 0.036424995713118906,\n",
       " 0.03637026623131412,\n",
       " 0.036315554755105776,\n",
       " 0.03626244645760137,\n",
       " 0.0362117119709761,\n",
       " 0.036160461507449546,\n",
       " 0.0361114597936362,\n",
       " 0.03606172337709873,\n",
       " 0.03601178133111306,\n",
       " 0.03596070166189469,\n",
       " 0.03590786797486839,\n",
       " 0.035857983017114674,\n",
       " 0.0358103551722895,\n",
       " 0.03576273254370667,\n",
       " 0.03571766680612544,\n",
       " 0.035671405712971505,\n",
       " 0.03562367205638535,\n",
       " 0.03557569715218706,\n",
       " 0.03552786536070969,\n",
       " 0.03548320630538404,\n",
       " 0.035438508534562055,\n",
       " 0.03539436786842179,\n",
       " 0.035347689132140564,\n",
       " 0.03530060554168805,\n",
       " 0.03525448490341471,\n",
       " 0.03520906700932949,\n",
       " 0.03516439781407091,\n",
       " 0.03511640819149828,\n",
       " 0.03506814890120282,\n",
       " 0.03502247291517724,\n",
       " 0.034977188104800605,\n",
       " 0.03493077268696924,\n",
       " 0.034886099044952684,\n",
       " 0.03484102418524673,\n",
       " 0.03479658735247836,\n",
       " 0.03475414147185432,\n",
       " 0.03471256506628227,\n",
       " 0.03467135060298233,\n",
       " 0.034630961449156304,\n",
       " 0.03458794554878184,\n",
       " 0.03454475269444802,\n",
       " 0.034500083691430254,\n",
       " 0.03445466990758672,\n",
       " 0.03441020259698953,\n",
       " 0.03436337702966385,\n",
       " 0.03431963624206173,\n",
       " 0.03427429901045848,\n",
       " 0.03422674751116892,\n",
       " 0.03417696698755676,\n",
       " 0.03412516953871239,\n",
       " 0.03407307081513633,\n",
       " 0.03402111668669906,\n",
       " 0.03396954079822058,\n",
       " 0.03392268775721211,\n",
       " 0.03387611113923626,\n",
       " 0.03383066805843565,\n",
       " 0.03378633121529865,\n",
       " 0.03374247813117189,\n",
       " 0.03369697315000012,\n",
       " 0.033651762895308565,\n",
       " 0.03360636638926503,\n",
       " 0.03356387785667512,\n",
       " 0.0335217139565438,\n",
       " 0.033479695449187455,\n",
       " 0.03343753808431098,\n",
       " 0.03339468503319265,\n",
       " 0.03335169462254383,\n",
       " 0.03330753936967913,\n",
       " 0.03326236854137478,\n",
       " 0.03321447767443804,\n",
       " 0.03316640896464003,\n",
       " 0.03311888800142359,\n",
       " 0.03307311468790309,\n",
       " 0.03302586175623837,\n",
       " 0.03297797826787802,\n",
       " 0.032929808910438174,\n",
       " 0.032883475883974514,\n",
       " 0.03283971048668672,\n",
       " 0.032795671349248136,\n",
       " 0.03275296983910875,\n",
       " 0.032711560482918706,\n",
       " 0.03266950729948832,\n",
       " 0.0326313152175774,\n",
       " 0.03259423405781059,\n",
       " 0.03255634223688843,\n",
       " 0.03251799910011174,\n",
       " 0.032478838134488,\n",
       " 0.032440044553888325,\n",
       " 0.03240061155421658,\n",
       " 0.03236162157174757,\n",
       " 0.03232371464058886,\n",
       " 0.032288042721317384,\n",
       " 0.03225036905750588,\n",
       " 0.032212850346073116,\n",
       " 0.032175777310643736,\n",
       " 0.03213787603781892,\n",
       " 0.03210072095757371,\n",
       " 0.03206473328678887,\n",
       " 0.032029595863900306,\n",
       " 0.03199452889747774,\n",
       " 0.03195803224552293,\n",
       " 0.030868094648497876,\n",
       " 0.030145565631011943,\n",
       " 0.02965430502178057,\n",
       " 0.029153093702332232,\n",
       " 0.028657399869027184,\n",
       " 0.028276124154981177,\n",
       " 0.027855708089878736,\n",
       " 0.027410594310531534,\n",
       " 0.026969770508560108,\n",
       " 0.02652864262540868,\n",
       " 0.02610944864225147,\n",
       " 0.025697977568850738,\n",
       " 0.025364508458506303,\n",
       " 0.025049665029523886,\n",
       " 0.024801511240611775,\n",
       " 0.024579067645320567,\n",
       " 0.024354756840630716,\n",
       " 0.02417883363535793,\n",
       " 0.02402115951929204,\n",
       " 0.023853978210273796,\n",
       " 0.02366454383902259,\n",
       " 0.0234933626086042,\n",
       " 0.023328798094140797,\n",
       " 0.02316486313529072,\n",
       " 0.02300082552809052,\n",
       " 0.022831425555454483,\n",
       " 0.02265940035543453,\n",
       " 0.022491226980044944,\n",
       " 0.02232311365510926,\n",
       " 0.02216562470053946,\n",
       " 0.022045408996242122,\n",
       " 0.021929232310322972,\n",
       " 0.021831847270788,\n",
       " 0.0217461175833296,\n",
       " 0.02165179416812818,\n",
       " 0.021583811814582594,\n",
       " 0.02155074711888693,\n",
       " 0.021529446233060915,\n",
       " 0.021514224988591932,\n",
       " 0.02150442978653812,\n",
       " 0.021496102676512332,\n",
       " 0.021484208523382124,\n",
       " 0.021480842607452907,\n",
       " 0.02146147192469338,\n",
       " 0.02144130022184044,\n",
       " 0.021424062855744268,\n",
       " 0.021402182146344102,\n",
       " 0.02139349941709654,\n",
       " 0.021402344831517487,\n",
       " 0.021404710132203533,\n",
       " 0.021404571877409847,\n",
       " 0.021406594146630018,\n",
       " 0.02140265190989451,\n",
       " 0.021392758982396214,\n",
       " 0.02139623467357405,\n",
       " 0.021414931156320406,\n",
       " 0.021432372477426857,\n",
       " 0.02144990083286887,\n",
       " 0.02147878844329469,\n",
       " 0.02149297514219957,\n",
       " 0.021509933936535216,\n",
       " 0.021538752810304373,\n",
       " 0.02156215827567429,\n",
       " 0.021589763686684228,\n",
       " 0.021621783651972523,\n",
       " 0.021647618594525495,\n",
       " 0.021671377241097307,\n",
       " 0.021685663531257882,\n",
       " 0.021696330721706902,\n",
       " 0.021704505338249285,\n",
       " 0.02170470602420957,\n",
       " 0.021699038122069754,\n",
       " 0.02168879853097074,\n",
       " 0.021685651769406847,\n",
       " 0.02168404865726881,\n",
       " 0.02168121222524392,\n",
       " 0.021689409134106764,\n",
       " 0.021697476648375628,\n",
       " 0.02170411975808612,\n",
       " 0.02171690354461376,\n",
       " 0.02174677780015681,\n",
       " 0.021776630147487645,\n",
       " 0.02180996566789513,\n",
       " 0.02184704065868704,\n",
       " 0.02188580739989384,\n",
       " 0.021923988947223163,\n",
       " 0.021962440100864056,\n",
       " 0.02200523656239106,\n",
       " 0.022049581966966336,\n",
       " 0.022087043638977358,\n",
       " 0.022122933223205462,\n",
       " 0.02216291297616749,\n",
       " 0.02220177272685339,\n",
       " 0.022245271829318732,\n",
       " 0.022286703134374378,\n",
       " 0.02232934566867044,\n",
       " 0.02236601478634796,\n",
       " 0.022404390723513256,\n",
       " 0.022437457391029616,\n",
       " 0.022470843589370865,\n",
       " 0.022500524413048107,\n",
       " 0.022529140591435622,\n",
       " 0.022561386470329455,\n",
       " 0.022596457632778608,\n",
       " 0.022629360175787084,\n",
       " 0.022668753400437835,\n",
       " 0.02270671907960725,\n",
       " 0.022741744076305796,\n",
       " 0.022775335972095283,\n",
       " 0.022812981260941702,\n",
       " 0.022852397243493448,\n",
       " 0.022892061834317728,\n",
       " 0.022935509314938443,\n",
       " 0.022972374824408344,\n",
       " 0.02301377661620705,\n",
       " 0.023051437207416852,\n",
       " 0.023095926837643527,\n",
       " 0.023132155229020603,\n",
       " 0.023176170227857073,\n",
       " 0.023218581792353067,\n",
       " 0.02327401500937802,\n",
       " 0.023328115972853863,\n",
       " 0.023381475373784155,\n",
       " 0.02343660370827864,\n",
       " 0.023495766010771548,\n",
       " 0.023563858854970653,\n",
       " 0.023632479187728157,\n",
       " 0.023697620609594457,\n",
       " 0.02376506434755898,\n",
       " 0.023827855089700607,\n",
       " 0.02388343394493734,\n",
       " 0.023938190317413285,\n",
       " 0.023995157444114457,\n",
       " 0.024049922925503526,\n",
       " 0.02409945064986182,\n",
       " 0.02414252766255527,\n",
       " 0.024181453436171913,\n",
       " 0.024218126132687246,\n",
       " 0.024253027732312964,\n",
       " 0.024284616682058828,\n",
       " 0.024312445847504964,\n",
       " 0.024342709924263028,\n",
       " 0.024381414781942008,\n",
       " 0.024418972341061267,\n",
       " 0.02446401781544742,\n",
       " 0.024508947506895574,\n",
       " 0.024558817595557194,\n",
       " 0.02461337842075451,\n",
       " 0.024670738406733485,\n",
       " 0.024724321710547042,\n",
       " 0.024778347519767492,\n",
       " 0.02483469979411263,\n",
       " 0.024888025103025724,\n",
       " 0.024942432272147912,\n",
       " 0.02499640719089965,\n",
       " 0.025049263113683995,\n",
       " 0.02510431792492855,\n",
       " 0.025155715744094746,\n",
       " 0.025200133301672367,\n",
       " 0.025253312649897063,\n",
       " 0.025314330112252825,\n",
       " 0.025374228962940747,\n",
       " 0.025437566638305282,\n",
       " 0.025498794094009247,\n",
       " 0.025559858523562292,\n",
       " 0.025620272011537618,\n",
       " 0.025671757236998615,\n",
       " 0.025726207622183563,\n",
       " 0.025773683923447015,\n",
       " 0.025823442589906348,\n",
       " 0.025873803453148148,\n",
       " 0.02592324467584557,\n",
       " 0.025973494183287617,\n",
       " 0.0260220243763318,\n",
       " 0.026068926161353916,\n",
       " 0.026114997168623026,\n",
       " 0.02616131494215961,\n",
       " 0.026215659847305735,\n",
       " 0.026270130071443187,\n",
       " 0.026320062430264236,\n",
       " 0.026370656171347213,\n",
       " 0.026420072849606437,\n",
       " 0.026464852402521635,\n",
       " 0.026508691535812735,\n",
       " 0.026551863291640984,\n",
       " 0.026600683768492853,\n",
       " 0.026653430460305733,\n",
       " 0.026709899804066174,\n",
       " 0.026768738851908343,\n",
       " 0.026826031722989824,\n",
       " 0.026884121084243488,\n",
       " 0.026943988808122665,\n",
       " 0.027008307836765697,\n",
       " 0.027074082705957875,\n",
       " 0.02713769902758287,\n",
       " 0.027201613791040958,\n",
       " 0.027265262572990997,\n",
       " 0.02732463971736474,\n",
       " 0.027383397557995702,\n",
       " 0.027445400429065812,\n",
       " 0.02750960317012291,\n",
       " 0.02757428710988123,\n",
       " 0.027639743688681353,\n",
       " 0.027706091965417828,\n",
       " 0.027769127814633338,\n",
       " 0.02783234022140147,\n",
       " 0.027895592693206444,\n",
       " 0.02795953817848871,\n",
       " 0.02802486044333437,\n",
       " 0.028086811576778226,\n",
       " 0.028152382432962534,\n",
       " 0.028219390676508912,\n",
       " 0.028285534694275766,\n",
       " 0.028354533625675596,\n",
       " 0.028421876568824077,\n",
       " 0.028492104289737367,\n",
       " 0.028564581858641226,\n",
       " 0.028633849140280176,\n",
       " 0.028701976373440345,\n",
       " 0.028770685957055973,\n",
       " 0.02883404021666797,\n",
       " 0.028898767793533373,\n",
       " 0.028963900988719316,\n",
       " 0.029028085703034508,\n",
       " 0.02909390173945961,\n",
       " 0.029156817876644172,\n",
       " 0.029219100743544613,\n",
       " 0.02927735957802461,\n",
       " 0.02933372140646988,\n",
       " 0.02938525134224606,\n",
       " 0.029432525706877523,\n",
       " 0.02948655099951346,\n",
       " 0.02953559174045729,\n",
       " 0.029584076379878588,\n",
       " 0.029635961279401126,\n",
       " 0.029685215659554846,\n",
       " 0.029736169657959978,\n",
       " 0.029789954184163605,\n",
       " 0.029846666910054383,\n",
       " 0.02990218113315293,\n",
       " 0.02995667612211873,\n",
       " 0.03001235095253858,\n",
       " 0.03006721288792437,\n",
       " 0.030124596700061672,\n",
       " 0.03017916555254696,\n",
       " 0.030232043043217405,\n",
       " 0.030292245313919792,\n",
       " 0.030357618688402064,\n",
       " 0.030426302716604608,\n",
       " 0.030497020109419588,\n",
       " 0.030566776729158668,\n",
       " 0.030636248308299877,\n",
       " 0.03070794364918372,\n",
       " 0.030776343385360547,\n",
       " 0.030844576260431328,\n",
       " 0.03091484458832477,\n",
       " 0.030986294388072502,\n",
       " 0.03105728573140217,\n",
       " 0.031127134679586107,\n",
       " 0.031194642307308687,\n",
       " 0.03126316677506033,\n",
       " 0.031334682130592435,\n",
       " 0.03140340863803986,\n",
       " 0.031472347996890214,\n",
       " 0.03154209620260566,\n",
       " 0.03160746984037789,\n",
       " 0.03166982204335659,\n",
       " 0.03173336688236352,\n",
       " 0.031795507775747384,\n",
       " 0.03185514161616886,\n",
       " 0.03191400140193395,\n",
       " 0.031971503672009335,\n",
       " 0.03202728834182527,\n",
       " 0.032081644145523065,\n",
       " 0.03213419987965335,\n",
       " 0.032181491099673894,\n",
       " 0.03222394739944791,\n",
       " 0.032264881256452695,\n",
       " 0.03231134191742375,\n",
       " 0.03235608645311744,\n",
       " 0.0324057107391812,\n",
       " 0.032459055130737206,\n",
       " 0.032519321660748585,\n",
       " 0.03258308710505199,\n",
       " 0.032649153323617265,\n",
       " 0.032714948521536606,\n",
       " 0.032782591551377194,\n",
       " 0.03284732744380875,\n",
       " 0.03291221145050267,\n",
       " 0.03298413991859441,\n",
       " 0.03306114776370721,\n",
       " 0.033142179430465074,\n",
       " 0.033227561203485884,\n",
       " 0.03331459048793867,\n",
       " 0.03340102754598398,\n",
       " 0.033484191276719026,\n",
       " 0.03356706439979957,\n",
       " 0.03364491766269284,\n",
       " 0.03372052175320933,\n",
       " 0.03379441302285567,\n",
       " 0.03386754431962349,\n",
       " 0.033937450992817086,\n",
       " 0.03400854959883189,\n",
       " 0.034077507136445306,\n",
       " 0.03414659183756804,\n",
       " 0.03421618921938207,\n",
       " 0.036141146049344534,\n",
       " 0.037897024743655916,\n",
       " 0.03920183891913259,\n",
       " 0.040656922219940696,\n",
       " 0.04192983325607956,\n",
       " 0.04307782396335048,\n",
       " 0.044162570264863754,\n",
       " 0.045086035946245,\n",
       " 0.045979649039419,\n",
       " 0.046715402047912635,\n",
       " 0.047423133350384554,\n",
       " 0.04802131907371192,\n",
       " 0.04858929259682454,\n",
       " 0.04909984068368158,\n",
       " 0.04957706522608651,\n",
       " 0.04997364878652858,\n",
       " 0.05028668858109445,\n",
       " 0.05062345065920232,\n",
       " 0.05093801601155411,\n",
       " 0.051228201017592644,\n",
       " 0.05152027178628531,\n",
       " 0.051756683309286414,\n",
       " 0.05193286276108883,\n",
       " 0.05213082517308171,\n",
       " 0.05234799848606147,\n",
       " 0.052565964906900735,\n",
       " 0.05282931433572436,\n",
       " 0.053109659908301216,\n",
       " 0.05340724288650148,\n",
       " 0.053685630627523004,\n",
       " 0.053957018868371974,\n",
       " 0.05424838985465032,\n",
       " 0.054518521730262594,\n",
       " 0.05477610497548451,\n",
       " 0.05502630563563946,\n",
       " 0.05525718219864526,\n",
       " 0.05552655909468077,\n",
       " 0.055774210354769316,\n",
       " 0.05600140664972432,\n",
       " 0.05624684586224766,\n",
       " 0.056482556260506606,\n",
       " 0.056706384834838176,\n",
       " 0.056909783348911044,\n",
       " 0.05710870467019651,\n",
       " 0.0572895171558193,\n",
       " 0.05745169146198019,\n",
       " 0.05759126393501148,\n",
       " 0.05774285337481665,\n",
       " 0.057887910525385444,\n",
       " 0.058016872006997976,\n",
       " 0.05813129448742763,\n",
       " 0.058227232803563136,\n",
       " 0.05832865018516171,\n",
       " 0.05841575499358226,\n",
       " 0.058486735993466814,\n",
       " 0.05855018415198508,\n",
       " 0.05861776226591275,\n",
       " 0.058690469969790035,\n",
       " 0.05876038507474737,\n",
       " 0.05884999180602977,\n",
       " 0.05894998851211025,\n",
       " 0.059049250344554965,\n",
       " 0.0591386120707873,\n",
       " 0.059227985399164275,\n",
       " 0.059298125064847634,\n",
       " 0.05935431464595595,\n",
       " 0.059403340763595686,\n",
       " 0.05943874746270208,\n",
       " 0.059474916574721585,\n",
       " 0.05950694760742639,\n",
       " 0.0595291862433808,\n",
       " 0.0595504370670608,\n",
       " 0.05957359618017894,\n",
       " 0.05958637263837297,\n",
       " 0.05958605147715961,\n",
       " 0.0595798176138093,\n",
       " 0.05957985914723485,\n",
       " 0.059586267891315305,\n",
       " 0.05959952731977792,\n",
       " 0.05960387983963691,\n",
       " 0.059614180764965434,\n",
       " 0.05961262404150863,\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = clf.evaluate(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c476996c-71ad-4289-ba50-7db20d0b6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import  MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45dd00c2-b55d-4ee3-8973-31940d237c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5: None -- [WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\urllib\\request.py:1354\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1354\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\http\\client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\http\\client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\http\\client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\http\\client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m \n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\http\\client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\http\\client.py:1418\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1418\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\http\\client.py:922\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;124;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mIPPROTO_TCP, socket\u001b[38;5;241m.\u001b[39mTCP_NODELAY, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\socket.py:808\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\socket.py:796\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    795\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 796\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py:277\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m   \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py:82\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m     80\u001b[0m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fd:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\urllib\\request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 525\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\urllib\\request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 542\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    543\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\urllib\\request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 502\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\urllib\\request.py:1397\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\urllib\\request.py:1357\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1358\u001b[0m r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10061] No connection could be made because the target machine actively refused it>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mbilenet \u001b[38;5;241m=\u001b[39m \u001b[43mMobileNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\applications\\mobilenet.py:305\u001b[0m, in \u001b[0;36mMobileNet\u001b[1;34m(input_shape, alpha, depth_multiplier, dropout, include_top, weights, input_tensor, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobilenet_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_tf_no_top.h5\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (alpha_text, rows)\n\u001b[0;32m    304\u001b[0m     weight_path \u001b[38;5;241m=\u001b[39m BASE_WEIGHT_PATH \u001b[38;5;241m+\u001b[39m model_name\n\u001b[1;32m--> 305\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m \u001b[43mdata_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_subdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m   model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py:281\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n\u001b[0;32m    280\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39merrno, e\u001b[38;5;241m.\u001b[39mreason))\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    283\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fpath):\n",
      "\u001b[1;31mException\u001b[0m: URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5: None -- [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    }
   ],
   "source": [
    "mbilenet = MobileNet(input_shape=(64,64,3),weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d669a4-b526-4754-a34b-9bbb9a86edc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
