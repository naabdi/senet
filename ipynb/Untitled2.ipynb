{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9896df0a-fbf7-43fd-b195-37c8db785d7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'stn2' from 'models.stn2' (D:\\MTPNet\\models\\stn2.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#from data_loader.generators import BELGA_Generator,TOPLOGO10_Generator,GTSRB_Generator,TT100K_Generator,PERSIAN_Generator\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmakemodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_proto_model\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_config\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_mse\n",
      "File \u001b[1;32mD:\\MTPNet\\models\\makemodels.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resnet,densenet,conv3b,mobilenet,vggnet,resnet12,densenet2\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_proto_model\u001b[39m(backbone,input_shape):\n",
      "File \u001b[1;32mD:\\MTPNet\\models\\densenet2.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m conv_block,dcp\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistances\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Euclidean_Distance\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstn2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stn2\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseNet121\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_densenet\u001b[39m(input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m3\u001b[39m)):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'stn2' from 'models.stn2' (D:\\MTPNet\\models\\stn2.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from data_loader.batchgenerator import GTSRB_Generator,TT100K_Generator,FLICKR32_Generator\n",
    "#from data_loader.generators import BELGA_Generator,TOPLOGO10_Generator,GTSRB_Generator,TT100K_Generator,PERSIAN_Generator\n",
    "import time\n",
    "from models.makemodels import make_proto_model\n",
    "from utils import load_config\n",
    "from models.losses import loss_mse\n",
    "import tensorflow as tf\n",
    "from data_loader import get_loader\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from models import resnet12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79de100-8e7e-41ca-84bc-c3bc085996a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_proto_model(backbone='resnet12',input_shape=(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dda6bc5-687f-442b-9f57-77fbbf89feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.blocks import res_block,conv_block,dcp\n",
    "from models.stn import stn\n",
    "from models.distances import Euclidean_Distance\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a24d377-ceff-43fd-9da7-cb38cc80065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet(input_shape = (64,64,3)):\n",
    "    H,W,C = input_shape\n",
    "    inp = keras.layers.Input([H,W,C])\n",
    "    resnet = resnet12.create_resnet12(input_shape=input_shape)\n",
    "    resnet.load_weights('model_files/pretrained_weights/resnet12_enc_tiered.h5')\n",
    "    res_encoder = keras.Model(inputs=resnet.inputs,outputs=resnet.get_layer('maxpool_stage_2').output,name='backbone')\n",
    "    x = res_encoder(inp)\n",
    "    x = keras.layers.Conv2D(\n",
    "        kernel_size=(1,1),filters=100,padding='same',kernel_initializer='he_normal')(x)\n",
    "    x = stn(x,filters=[100,100,100])\n",
    "    x = conv_block(x,kernel_size=(5,5),n_filters=100,strides=(1,1))\n",
    "    x = dcp(x,n_filters=100,kernel_size=(3,3))\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(units=300,activation='linear',kernel_initializer=\"he_normal\")(x)\n",
    "    return keras.Model(inp,x,name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40c9d520-28d2-4ee5-9af1-0b4fb601f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = create_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ebc40-3931-4e4b-823c-0657b6220659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f531a9c2-f489-468d-ac29-3102906be6e7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f531a9c2-f489-468d-ac29-3102906be6e7/assets\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'cl.h5')  # Save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edac58-1c7d-4819-a3ab-cec8a9b9cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('cl.h5') # Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be65167-d5a6-4a0e-9f3f-15066ee12834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb79c2-1f94-4165-aed3-b166394e2832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db4a30d-78b3-4dc7-ba18-d8378a56ee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "clf.save('clf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a13f1330-25a1-4e65-94dc-46f130159465",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclf.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1271\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m   inbound_node \u001b[38;5;241m=\u001b[39m inbound_layer\u001b[38;5;241m.\u001b[39m_inbound_nodes[inbound_node_index]\n\u001b[0;32m   1270\u001b[0m   input_tensors\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m-> 1271\u001b[0m       \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43minbound_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43minbound_tensor_index\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1273\u001b[0m   \u001b[38;5;66;03m# We received a constant w/ no Keras history attached\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m   input_tensors\u001b[38;5;241m.\u001b[39mappend(inbound_tensor_index)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "keras.models.load_model('clf.h5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f00ab39-bc20-4dee-9e4e-10ec8c20fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl2 = tf.saved_model.load('clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c1669df-9a27-4978-9072-9a8fc7c87183",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = cl2.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de960553-bfb9-4d1b-968f-2ffe09047730",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.ones((128,64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91e351aa-b7ec-43d0-adcc-aba22aa474b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Nariman\\AppData\\Local\\Temp\\tmpox_07vuf\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(clf)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e52525ad-715b-4894-aeae-f31576be41de",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bytes' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtflite_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bytes' object is not callable"
     ]
    }
   ],
   "source": [
    "tflite_model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d42ec0ba-cabd-481a-b304-1aaba1581c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.load_weights('model_files/best_densenet_gtsrb2tt100k_14011024.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb818c0b-97b5-4f42-9703-a1207783beaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'dense_5')>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_layer('encoder').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d215cab-ead3-4946-9250-7279b6a2b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.layers.Input((64,64,3))\n",
    "enc = keras.Model(inputs=clf.get_layer('encoder').input,outputs=clf.get_layer('encoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aee275c7-36b8-436f-80a2-77c7525b608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d19dfda8-c3dc-48f8-9a4b-fe3878d6134a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all data\n"
     ]
    }
   ],
   "source": [
    "loader = get_loader('gtsrb2tt100k') \n",
    "test_generator = loader.get_test_generator(batch=128,dim=64,type='tt100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84bfd3e4-d12d-4143-9fe0-1636e1bbe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = iter(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e51bd03c-8321-48d8-82da-2ad09b9df5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Xs,Xq],y = next(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32b8aba4-d4a6-474a-a64c-3bf2af48735c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([36, 300])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zs = enc(Xs)\n",
    "Zs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf06e6bd-ab79-4a97-b77d-eac3fdc321a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 300])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zq = enc(Xq)\n",
    "Zq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fce83b42-e29c-4384-84f1-3983b23340f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17baf233dc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xs[0]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afecf598-fd47-4763-a8f0-9c8c43ef21a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(np.arange(36),num_classes=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48558608-9f24-414d-ba3f-fc95715a9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4561f61b-fe72-4b2f-b5d7-fa744eba41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1,n_jobs=-1,metric='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3f81ae8-ed46-4700-a7d0-6789b6559c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(Zs,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8647eb7e-7353-49a1-9aa0-76005aa57b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796875"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(Zq,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5264c383-0b1f-4e92-9403-01a98f0c8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dee9d946-1322-453c-8f25-8e165a426f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:27<00:00,  3.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8197244623655914"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "y_train = to_categorical(np.arange(36),num_classes=36)\n",
    "for z in tqdm(test_generator):\n",
    "    [Xs,Xq],y_test = z\n",
    "    Zq = enc(Xq)\n",
    "    acc += knn.score(Zq,y_test)\n",
    "acc / len(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fd3e7f4-4da5-400e-8bb7-fbfb23fafef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62c620bf-058a-4ada-b9a0-d1a348b39183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "enc.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e81b5a86-55f0-4ab0-b8ed-2a4c8ce26c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fe \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoder.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:1271\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m   inbound_node \u001b[38;5;241m=\u001b[39m inbound_layer\u001b[38;5;241m.\u001b[39m_inbound_nodes[inbound_node_index]\n\u001b[0;32m   1270\u001b[0m   input_tensors\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m-> 1271\u001b[0m       \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43minbound_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43minbound_tensor_index\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1273\u001b[0m   \u001b[38;5;66;03m# We received a constant w/ no Keras history attached\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m   input_tensors\u001b[38;5;241m.\u001b[39mappend(inbound_tensor_index)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "fe = keras.models.load_model('encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f9657f-09c3-4975-b79e-a65b5a7b1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MaxPooling2D,Conv2D,Flatten,Dense,Input,GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "class Localization(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 filters_1: int, \n",
    "                 filters_2: int, \n",
    "                 fc_units: int, \n",
    "                 kernel_size=(5,5),\n",
    "                 pool_size=(2,2),\n",
    "                 name='localization', \n",
    "                 **kwargs):\n",
    "        super(Localization, self).__init__(**kwargs)\n",
    "        self.filters_1 = filters_1\n",
    "        self.filters_2 = filters_2\n",
    "        self.fc_units = fc_units\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_size = pool_size\n",
    "        self.network = keras.Sequential(\n",
    "            [\n",
    "                MaxPooling2D(pool_size=pool_size, name=name+'_mp_1'),\n",
    "                Conv2D(filters=filters_1, \n",
    "                       kernel_size=kernel_size, \n",
    "                       padding='same', \n",
    "                       strides=1, \n",
    "                       activation='relu',\n",
    "                       name=name+'_c_1'),\n",
    "                MaxPooling2D(pool_size=pool_size, name=name+'_mp_2'),\n",
    "                Conv2D(filters=filters_2, \n",
    "                       kernel_size=kernel_size, \n",
    "                       padding='same', \n",
    "                       strides=1, \n",
    "                       activation='relu',\n",
    "                       name=name+'_c_2'),\n",
    "                MaxPooling2D(pool_size=pool_size, name=name+'_mp_3'),\n",
    "                Flatten(name=name+'_fl'),\n",
    "                Dense(fc_units, activation='relu', name=name+'_d_1'),\n",
    "                Dense(6, activation=None, \n",
    "                      bias_initializer=tf.keras.initializers.constant\\\n",
    "                      ([1.0, 0.0, 0.0, 0.0, 1.0, 0.0]), \n",
    "                      kernel_initializer='zeros',\n",
    "                      name=name+'_d_2'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"Building Localization Network with input shape:\", input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [None, 6]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        theta = self.network(inputs)\n",
    "        theta = tf.keras.layers.Reshape((2, 3))(theta)\n",
    "        return theta\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Localization, self).get_config()\n",
    "        config.update({\n",
    "            'filters_1': self.filters_1,\n",
    "            'filters_2': self.filters_2,\n",
    "            'fc_units': self.fc_units,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'pool_size': self.pool_size,\n",
    "        })\n",
    "        return config\n",
    "     \n",
    "class BilinearInterpolation(tf.keras.layers.Layer):\n",
    "    def __init__(self, height=48, width=48):\n",
    "        super(BilinearInterpolation, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [None, self.height, self.width, 1]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'height': self.height,\n",
    "            'width': self.width,\n",
    "        }\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(\"Building Bilinear Interpolation Layer with input shape:\", input_shape)\n",
    "\n",
    "    def advance_indexing(self, inputs, x, y):\n",
    "        '''\n",
    "        Utility function to get pixel value for coordinate\n",
    "        vectors x and y from a  4D tensor image.\n",
    "        '''        \n",
    "        shape = tf.shape(inputs)\n",
    "        batch_size, _, _ = shape[0], shape[1], shape[2]\n",
    "        \n",
    "        batch_idx = tf.range(0, batch_size)\n",
    "        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "        b = tf.tile(batch_idx, (1, self.height, self.width))\n",
    "        indices = tf.stack([b, y, x], 3)\n",
    "        return tf.gather_nd(inputs, indices)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        images, theta = inputs\n",
    "        sampling_grid = self.grid_generator(batch=tf.shape(images)[0])\n",
    "        return self.interpolate(images, sampling_grid, theta)\n",
    "\n",
    "    def grid_generator(self, batch):\n",
    "        '''\n",
    "        This function returns a sampling grid, which when\n",
    "        used with the bilinear sampler on the input feature\n",
    "        map, will create an output feature map that is an\n",
    "        affine transformation of the input feature map.\n",
    "        '''\n",
    "        # create normalized 2D grid\n",
    "        x = tf.linspace(-1, 1, self.width)\n",
    "        y = tf.linspace(-1, 1, self.height)\n",
    "        # x and y are selected in the range of -1 to 1 so the the transformation happens considering the center\n",
    "        # of the image as the origin. The images will be later scaled up.\n",
    "        xx, yy = tf.meshgrid(x, y)\n",
    "            \n",
    "        # flatten\n",
    "        xx = tf.reshape(xx, (-1,))\n",
    "        yy = tf.reshape(yy, (-1,))\n",
    "\n",
    "        # reshape to [x_t, y_t , 1] - (homogeneous form)\n",
    "        homogenous_coordinates = tf.stack([xx, yy, tf.ones_like(xx)])\n",
    "        # # repeat grid num_batch times\n",
    "        # sampling_grid = np.resize(sampling_grid, (num_batch, 3, H*W))\n",
    "        # repeat grid num_batch times\n",
    "        homogenous_coordinates = tf.expand_dims(homogenous_coordinates, axis=0)\n",
    "        homogenous_coordinates = tf.tile(homogenous_coordinates, tf.stack([batch, 1, 1]))\n",
    "        # homogenous_coordinates = tf.tile(homogenous_coordinates, [batch, 1, 1])\n",
    "\n",
    "        # cast to float32 (required for matmul)\n",
    "        homogenous_coordinates = tf.cast(homogenous_coordinates, dtype=tf.float32)\n",
    "\n",
    "        return homogenous_coordinates\n",
    "    \n",
    "    def interpolate(self, images, grid, theta):\n",
    "        '''\n",
    "        Performs bilinear sampling of the input images according to the\n",
    "        normalized coordinates provided by the sampling grid. Note that\n",
    "        the sampling is done identically for each channel of the input.\n",
    "        '''\n",
    "\n",
    "        with tf.name_scope(\"Transformation\"):\n",
    "            # transform the sampling grid - batch multiply\n",
    "            transformed = tf.matmul(theta, grid)\n",
    "            # batch grid has shape (num_batch, 2, H*W)\n",
    "\n",
    "            # reshape to (num_batch, H, W, 2)\n",
    "            transformed = tf.transpose(transformed, perm=[0, 2, 1])\n",
    "            transformed = tf.reshape(transformed, [-1, self.height, self.width, 2])\n",
    "                \n",
    "            x_transformed = transformed[:, :, :, 0]\n",
    "            y_transformed = transformed[:, :, :, 1]\n",
    "                \n",
    "            # rescale x and y to [0, W-1/H-1]\n",
    "            x = ((x_transformed + 1.) * tf.cast(self.width, dtype=tf.float32)) * 0.5\n",
    "            y = ((y_transformed + 1.) * tf.cast(self.height, dtype=tf.float32)) * 0.5\n",
    "\n",
    "        with tf.name_scope(\"VariableCasting\"):\n",
    "            # grab 4 nearest corner points for each (x_i, y_i)\n",
    "            x0 = tf.cast(tf.math.floor(x), dtype=tf.int32)\n",
    "            x1 = x0 + 1\n",
    "            y0 = tf.cast(tf.math.floor(y), dtype=tf.int32)\n",
    "            y1 = y0 + 1\n",
    "\n",
    "            # clip to range [0, H-1/W-1] to not violate img boundaries\n",
    "            x0 = tf.clip_by_value(x0, 0, self.width-1)\n",
    "            x1 = tf.clip_by_value(x1, 0, self.width-1)\n",
    "            y0 = tf.clip_by_value(y0, 0, self.height-1)\n",
    "            y1 = tf.clip_by_value(y1, 0, self.height-1)\n",
    "            x = tf.clip_by_value(x, 0, tf.cast(self.width, dtype=tf.float32)-1.0)\n",
    "            y = tf.clip_by_value(y, 0, tf.cast(self.height, dtype=tf.float32)-1)\n",
    "\n",
    "        with tf.name_scope(\"AdvanceIndexing\"):\n",
    "            # get pixel value at corner coords\n",
    "            Ia = self.advance_indexing(images, x0, y0)\n",
    "            Ib = self.advance_indexing(images, x0, y1)\n",
    "            Ic = self.advance_indexing(images, x1, y0)\n",
    "            Id = self.advance_indexing(images, x1, y1)\n",
    "\n",
    "        with tf.name_scope(\"Interpolation\"):\n",
    "            # recast as float for delta calculation\n",
    "            x0 = tf.cast(x0, dtype=tf.float32)\n",
    "            x1 = tf.cast(x1, dtype=tf.float32)\n",
    "            y0 = tf.cast(y0, dtype=tf.float32)\n",
    "            y1 = tf.cast(y1, dtype=tf.float32)\n",
    "                            \n",
    "            # calculate deltas\n",
    "            wa = (x1-x) * (y1-y)\n",
    "            wb = (x1-x) * (y-y0)\n",
    "            wc = (x-x0) * (y1-y)\n",
    "            wd = (x-x0) * (y-y0)\n",
    "\n",
    "            # add dimension for addition\n",
    "            wa = tf.expand_dims(wa, axis=3)\n",
    "            wb = tf.expand_dims(wb, axis=3)\n",
    "            wc = tf.expand_dims(wc, axis=3)\n",
    "            wd = tf.expand_dims(wd, axis=3)\n",
    "                        \n",
    "        return tf.math.add_n([wa*Ia + wb*Ib + wc*Ic + wd*Id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf53b83-ccc8-4e73-8823-8e8583046b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from models.blocks import conv_block,dcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b2b61ad-0414-439e-a80f-61981e88b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stn(x):\n",
    "    theta = Localization(100,100,100)(x)\n",
    "    h,w = [x.shape[1],x.shape[2]]\n",
    "    return BilinearInterpolation(height=h,width=w)([x, theta]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0375099a-72cc-4863-8a3d-492e13bb6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 8, 8, 100)\n",
      "Building Bilinear Interpolation Layer with input shape: [TensorShape([None, 8, 8, 100]), TensorShape([None, 2, 3])]\n"
     ]
    }
   ],
   "source": [
    "inp = keras.layers.Input((64,64,3))\n",
    "densnet = DenseNet121(input_shape=(64,64,3),weights='imagenet',include_top=False)\n",
    "dens_encoder = keras.Model(inputs=densnet.inputs,outputs=densnet.get_layer('conv3_block1_concat').output)\n",
    "x = dens_encoder(inp)\n",
    "x = keras.layers.Conv2D(kernel_size=(1,1),filters=100,padding='same',kernel_initializer='he_normal')(x)\n",
    "x = stn(x)\n",
    "x = conv_block(x,kernel_size=(3,3),n_filters=100,strides=(1,1))\n",
    "x = dcp(x,n_filters=100,kernel_size=(3,3))\n",
    "x = keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(units=400,activation='linear',kernel_initializer=\"he_normal\")(x)\n",
    "c = keras.Model(inp,outputs=x,name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebc1d794-681c-4b13-a074-54399e62705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "c.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "939fa5be-a650-409a-a7ba-67c6d289ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 8, 8, 100)\n",
      "Building Bilinear Interpolation Layer with input shape: [TensorShape([None, 8, 8, 100]), TensorShape([None, 2, 3])]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "c2 = keras.models.load_model('test.h5',custom_objects={'Localization':Localization,'BilinearInterpolation':BilinearInterpolation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f1d0a3d-caf4-4bb2-b990-69b7a4fcc7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " model_5 (Functional)           (None, 8, 8, 160)    436032      ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 100)    16100       ['model_5[0][0]']                \n",
      "                                                                                                  \n",
      " localization_8 (Localization)  (None, 2, 3)         510906      ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " bilinear_interpolation_5 (Bili  (None, 8, 8, 100)   0           ['conv2d_16[0][0]',              \n",
      " nearInterpolation)                                               'localization_8[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 6, 6, 100)    90100       ['bilinear_interpolation_5[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 6, 6, 100)   24          ['conv2d_17[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 6, 6, 100)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 6, 6, 100)    90100       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 6, 6, 100)    90100       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 6, 6, 100)    90100       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 6, 6, 100)    90100       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 6, 6, 400)    0           ['conv2d_18[0][0]',              \n",
      "                                                                  'conv2d_19[0][0]',              \n",
      "                                                                  'conv2d_20[0][0]',              \n",
      "                                                                  'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 6, 6, 400)   24          ['concatenate_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 6, 6, 400)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 400)   0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 3600)         0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 400)          1440400     ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,853,986\n",
      "Trainable params: 2,849,546\n",
      "Non-trainable params: 4,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "c2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2010f-e9ee-48fa-9260-44219933bb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
