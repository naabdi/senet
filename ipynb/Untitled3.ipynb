{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b85ae1d-c8f9-45e1-ad2d-4fa25652f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from utils import load_config\n",
    "from gpu.gpu import set_gpu_memory_growth\n",
    "import argparse\n",
    "from models.makemodels import make_vanilla_model,make_proto_model\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array, ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from data_loader import get_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71349491-9dad-4d42-b6b7-adbf8fdb50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'datasets/GTSRB/GTSRB_Test'\n",
    "X = []\n",
    "for f in os.listdir(test_path):\n",
    "    file_path = os.path.join(test_path,f)\n",
    "    X += [img_to_array(load_img(file_path,target_size=(64,64)))]\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47bbaba5-c7a5-4bbe-8101-8e6d0bbd5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/GTSRB/GT-final_test.csv',sep=';')\n",
    "y_true = to_categorical(np.array(df['ClassId']),num_classes=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c26eaf8c-d34e-4b48-a02c-889fcc3e53b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "datapath = 'datasets/GTSRB/all'\n",
    "tr_datagen = ImageDataGenerator(rotation_range = 20,shear_range=0.2,height_shift_range=0.1,width_shift_range=0.1,horizontal_flip=True)\n",
    "train_gen = tr_datagen.flow_from_directory(datapath,batch_size=128,class_mode='categorical',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6e68f0-c7ed-46ac-8e1e-493f9f7f8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.makemodels import make_proto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "704d18f5-a497-4fdd-9ffa-803e6cb7f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_proto_model(backbone='densenet',input_shape=(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd9c0a74-3111-49b1-9956-9c2c6014d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.load_weights('model_files/best_densenet2_gtsrb2tt100k_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92d42601-5472-421e-a826-0b6c1b89c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.layers.Input((64,64,3))\n",
    "enc = keras.Model(inputs=clf.get_layer('encoder').input,outputs=clf.get_layer('encoder').output)\n",
    "x = enc(inp)\n",
    "x = keras.layers.Dense(100,activation='relu')(x)\n",
    "x = keras.layers.Dense(43,activation='softmax')(x)\n",
    "clf_encoder = keras.Model(inputs=inp,outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a009c14-a4dc-45f5-8e77-7680c77c89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_encoder,encoder = make_vanilla_model(backbone='densenet',n_class=43,dim=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f287277-44b9-41cf-8146-a9d56ef333c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_encoder,encoder = make_vanilla_model(backbone='conv3b',n_class=43,dim=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc08315c-4732-4136-8dbe-1062a041c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in clf_encoder.layers[:2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "14426085-caf8-4287-a9a4-eb906a6c1ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " model_19 (Functional)       (None, 300)               2173926   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 43)                4343      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,208,369\n",
      "Trainable params: 34,443\n",
      "Non-trainable params: 2,173,926\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6afa75cb-6001-4895-853b-0f2c8defcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = CategoricalAccuracy()\n",
    "train_loss_tracker = keras.metrics.Mean(name='loss')\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
    "loss_fun = keras.losses.CategoricalCrossentropy()\n",
    "clf_encoder.compile(optimizer=optimizer,loss=loss_fun,metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd5166e7-10ec-49d6-9da3-cd07e3246361",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.arange(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4843ba5-b93e-42af-a558-cbc36deada6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X) // 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5ecc969-d8b5-4af9-9c4a-eda60a9e55ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12630"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2269ff7-f6e9-4840-895d-701130d0ecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  1, 38, 33, 11, 38, 18, 12, 25, 35], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_true[0:10],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04290177-3928-4975-8af6-f0334c2b17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_encoder(X[indexes[0:1263]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7779bde2-9642-4ff4-b347-3ef0c7bb4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    acc = 0\n",
    "    for i in range(10):\n",
    "        y_pred = clf_encoder(X[indexes[i*1263:(i+1)*1263]])\n",
    "        acc += np.mean(keras.metrics.categorical_accuracy(y_true[i*1263:(i+1)*1263],y_pred))\n",
    "    return acc / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "069d7f7c-301f-4b76-89f2-c877bf4b2169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 49s 159ms/step - loss: 0.1683 - categorical_accuracy: 0.9452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac5120b8b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_encoder.fit(train_gen,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ab1a6e8-d1f0-4b1c-ae7c-c742fe946060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9389548659324646"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d5f56048-02b2-4c12-9ed2-88e95c03956a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 51s 158ms/step - loss: 0.1508 - categorical_accuracy: 0.9472\n",
      "best accuracy = 0.9241\n",
      "307/307 [==============================] - 49s 159ms/step - loss: 0.1254 - categorical_accuracy: 0.9538\n",
      "best accuracy = 0.9277\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for _ in range(2):\n",
    "    clf_encoder.fit(train_gen,epochs=1)\n",
    "    #y_pred = clf_encoder(X)\n",
    "    #acc = np.mean(keras.metrics.categorical_accuracy(y_true,y_pred))\n",
    "    acc = test()\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        print(f'best accuracy = {best_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd6c0662-681d-438c-a7e1-e116823a7808",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_proto_model(backbone='densenet',input_shape=(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02917eb0-2a7e-4f6c-98d8-2dabe3d47c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.load_weights('model_files/best_densenet_belga2flick_mse_ft.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68363f2c-09d9-4c6e-9bb2-a1fc1488a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.layers.Input((64,64,3))\n",
    "enc = keras.Model(inputs=clf.get_layer('encoder').input,outputs=clf.get_layer('encoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41d5ae58-b63b-4169-9efa-fee4ef99cd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all data\n"
     ]
    }
   ],
   "source": [
    "loader = get_loader('gtsrb') \n",
    "test_generator = loader.get_test_generator(batch=8,dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c977e23a-6f48-4b7b-886d-65bb41cea118",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = iter(test_generator)\n",
    "[Xs,Xq],y = next(t)\n",
    "Zs = enc(Xs)\n",
    "Zq = enc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f223d73-3ed2-467e-be54-32cdda755383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6b19173-94f1-4298-abd5-310392097d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1,n_jobs=-1,metric='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "571773ab-04fc-4b67-b35b-a522eb4c7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "start = time()\n",
    "y_train = to_categorical(np.arange(36),num_classes=36)\n",
    "knn.fit(Zs,y_train);\n",
    "pb = tf.keras.utils.Progbar(len(test_generator),verbose=1)\n",
    "for i,z in enumerate(test_generator):\n",
    "    [Xs,Xq],y_test = z\n",
    "    Zq = enc(Xq)\n",
    "    acc += knn.score(Zq,y_test)\n",
    "    values=[('test acc',(acc / (i+1)))]\n",
    "    pb.add(1,values=values)\n",
    "end = time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7481fec9-82f2-4e37-a77c-6d6e904eed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(np.arange(43),num_classes=43)\n",
    "knn.fit(Zs,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35b6b245-8e66-4e30-8adc-eaea31071a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930720506730008"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(Zq,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be16dde-dbda-432a-b2d0-565c8898c87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
